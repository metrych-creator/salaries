{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "96b496f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%pip install openpyxl -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "797e9d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ccf998b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Train_rev1.csv', index_col='Id')\n",
    "df_test = pd.read_csv('data/Test_rev1.csv', index_col='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1065321d-3e4c-4859-bcea-c506d0264b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (244768, 11)\n",
      "Test data shape:  (122463, 9)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data shape: \", df.shape)\n",
    "print(\"Test data shape: \", df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "acc726b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12612628</th>\n",
       "      <td>Engineering Systems Analyst</td>\n",
       "      <td>Engineering Systems Analyst Dorking Surrey Sal...</td>\n",
       "      <td>Dorking, Surrey, Surrey</td>\n",
       "      <td>Dorking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12612830</th>\n",
       "      <td>Stress Engineer Glasgow</td>\n",
       "      <td>Stress Engineer Glasgow Salary **** to **** We...</td>\n",
       "      <td>Glasgow, Scotland, Scotland</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 35000/annum 25-35K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12612844</th>\n",
       "      <td>Modelling and simulation analyst</td>\n",
       "      <td>Mathematical Modeller / Simulation Analyst / O...</td>\n",
       "      <td>Hampshire, South East, South East</td>\n",
       "      <td>Hampshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 40000/annum 20-40K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Title  \\\n",
       "Id                                           \n",
       "12612628       Engineering Systems Analyst   \n",
       "12612830           Stress Engineer Glasgow   \n",
       "12612844  Modelling and simulation analyst   \n",
       "\n",
       "                                            FullDescription  \\\n",
       "Id                                                            \n",
       "12612628  Engineering Systems Analyst Dorking Surrey Sal...   \n",
       "12612830  Stress Engineer Glasgow Salary **** to **** We...   \n",
       "12612844  Mathematical Modeller / Simulation Analyst / O...   \n",
       "\n",
       "                                LocationRaw LocationNormalized ContractType  \\\n",
       "Id                                                                            \n",
       "12612628            Dorking, Surrey, Surrey            Dorking          NaN   \n",
       "12612830        Glasgow, Scotland, Scotland            Glasgow          NaN   \n",
       "12612844  Hampshire, South East, South East          Hampshire          NaN   \n",
       "\n",
       "         ContractTime                       Company          Category  \\\n",
       "Id                                                                      \n",
       "12612628    permanent  Gregory Martin International  Engineering Jobs   \n",
       "12612830    permanent  Gregory Martin International  Engineering Jobs   \n",
       "12612844    permanent  Gregory Martin International  Engineering Jobs   \n",
       "\n",
       "                           SalaryRaw  SalaryNormalized        SourceName  \n",
       "Id                                                                        \n",
       "12612628  20000 - 30000/annum 20-30K             25000  cv-library.co.uk  \n",
       "12612830  25000 - 35000/annum 25-35K             30000  cv-library.co.uk  \n",
       "12612844  20000 - 40000/annum 20-40K             30000  cv-library.co.uk  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2a3ef045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 244768 entries, 12612628 to 72705235\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   Title               244767 non-null  object\n",
      " 1   FullDescription     244768 non-null  object\n",
      " 2   LocationRaw         244768 non-null  object\n",
      " 3   LocationNormalized  244768 non-null  object\n",
      " 4   ContractType        65442 non-null   object\n",
      " 5   ContractTime        180863 non-null  object\n",
      " 6   Company             212338 non-null  object\n",
      " 7   Category            244768 non-null  object\n",
      " 8   SalaryRaw           244768 non-null  object\n",
      " 9   SalaryNormalized    244768 non-null  int64 \n",
      " 10  SourceName          244767 non-null  object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 22.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a14b2297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>244767</td>\n",
       "      <td>244768</td>\n",
       "      <td>244768</td>\n",
       "      <td>244768</td>\n",
       "      <td>65442</td>\n",
       "      <td>180863</td>\n",
       "      <td>212338</td>\n",
       "      <td>244768</td>\n",
       "      <td>244768</td>\n",
       "      <td>244768.000000</td>\n",
       "      <td>244767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>135435</td>\n",
       "      <td>242138</td>\n",
       "      <td>20986</td>\n",
       "      <td>2732</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20812</td>\n",
       "      <td>29</td>\n",
       "      <td>97286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Business Development Manager</td>\n",
       "      <td>What is expected of you as a Registered Nurse ...</td>\n",
       "      <td>London</td>\n",
       "      <td>UK</td>\n",
       "      <td>full_time</td>\n",
       "      <td>permanent</td>\n",
       "      <td>UKStaffsearch</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>50,000-74,999 yearly</td>\n",
       "      <td>NaN</td>\n",
       "      <td>totaljobs.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>921</td>\n",
       "      <td>18</td>\n",
       "      <td>15605</td>\n",
       "      <td>41093</td>\n",
       "      <td>57538</td>\n",
       "      <td>151521</td>\n",
       "      <td>4997</td>\n",
       "      <td>38483</td>\n",
       "      <td>1923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34122.577576</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17640.543124</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21500.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42500.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Title  \\\n",
       "count                         244767   \n",
       "unique                        135435   \n",
       "top     Business Development Manager   \n",
       "freq                             921   \n",
       "mean                             NaN   \n",
       "std                              NaN   \n",
       "min                              NaN   \n",
       "25%                              NaN   \n",
       "50%                              NaN   \n",
       "75%                              NaN   \n",
       "max                              NaN   \n",
       "\n",
       "                                          FullDescription LocationRaw  \\\n",
       "count                                              244768      244768   \n",
       "unique                                             242138       20986   \n",
       "top     What is expected of you as a Registered Nurse ...      London   \n",
       "freq                                                   18       15605   \n",
       "mean                                                  NaN         NaN   \n",
       "std                                                   NaN         NaN   \n",
       "min                                                   NaN         NaN   \n",
       "25%                                                   NaN         NaN   \n",
       "50%                                                   NaN         NaN   \n",
       "75%                                                   NaN         NaN   \n",
       "max                                                   NaN         NaN   \n",
       "\n",
       "       LocationNormalized ContractType ContractTime        Company Category  \\\n",
       "count              244768        65442       180863         212338   244768   \n",
       "unique               2732            2            2          20812       29   \n",
       "top                    UK    full_time    permanent  UKStaffsearch  IT Jobs   \n",
       "freq                41093        57538       151521           4997    38483   \n",
       "mean                  NaN          NaN          NaN            NaN      NaN   \n",
       "std                   NaN          NaN          NaN            NaN      NaN   \n",
       "min                   NaN          NaN          NaN            NaN      NaN   \n",
       "25%                   NaN          NaN          NaN            NaN      NaN   \n",
       "50%                   NaN          NaN          NaN            NaN      NaN   \n",
       "75%                   NaN          NaN          NaN            NaN      NaN   \n",
       "max                   NaN          NaN          NaN            NaN      NaN   \n",
       "\n",
       "                   SalaryRaw  SalaryNormalized     SourceName  \n",
       "count                 244768     244768.000000         244767  \n",
       "unique                 97286               NaN            167  \n",
       "top     50,000-74,999 yearly               NaN  totaljobs.com  \n",
       "freq                    1923               NaN          48149  \n",
       "mean                     NaN      34122.577576            NaN  \n",
       "std                      NaN      17640.543124            NaN  \n",
       "min                      NaN       5000.000000            NaN  \n",
       "25%                      NaN      21500.000000            NaN  \n",
       "50%                      NaN      30000.000000            NaN  \n",
       "75%                      NaN      42500.000000            NaN  \n",
       "max                      NaN     200000.000000            NaN  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7383c5",
   "metadata": {},
   "source": [
    "# 1. Drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8cc4aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['SalaryRaw', 'LocationRaw'], inplace=True)\n",
    "df_test.drop(columns=['LocationRaw'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "adcd8b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (244768, 9)\n",
      "Test data shape:  (122463, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data shape: \", df.shape)\n",
    "print(\"Test data shape: \", df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1bae63",
   "metadata": {},
   "source": [
    "# 2. Fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b4036bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Title                  0.000409\n",
       "FullDescription        0.000000\n",
       "LocationNormalized     0.000000\n",
       "ContractType          73.263662\n",
       "ContractTime          26.108397\n",
       "Company               13.249281\n",
       "Category               0.000000\n",
       "SalaryNormalized       0.000000\n",
       "SourceName             0.000409\n",
       "dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Missing values:')\n",
    "df.isna().sum()/df.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dc875107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_train_test(train_df, test_df):\n",
    "    # Store the fill values from train\n",
    "    fill_values = {}\n",
    "    \n",
    "    for col in train_df.columns:\n",
    "        if train_df[col].dtype == 'O':  # object/string\n",
    "            fill_values[col] = train_df[col].mode()[0]\n",
    "        else:  # numbers\n",
    "            fill_values[col] = train_df[col].mean()\n",
    "    \n",
    "    # Fill train and test with the same values\n",
    "    train_filled = train_df.fillna(fill_values)\n",
    "    test_filled = test_df.fillna(fill_values)\n",
    "    \n",
    "    return train_filled, test_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a5bcae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, df_test = fill_missing_train_test(df, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "321317d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title                 0.0\n",
       "FullDescription       0.0\n",
       "LocationNormalized    0.0\n",
       "ContractType          0.0\n",
       "ContractTime          0.0\n",
       "Company               0.0\n",
       "Category              0.0\n",
       "SalaryNormalized      0.0\n",
       "SourceName            0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()/df.shape[0]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6f69de",
   "metadata": {},
   "source": [
    "# 3. Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eaa60958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset duplicates BEFORE removing:  1\n",
      "Train dataset duplicates AFTER removing:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Train dataset duplicates BEFORE removing: \", df.duplicated().sum())\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(\"Train dataset duplicates AFTER removing: \", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aa8a2e-6560-4208-8a3f-ef86300dc686",
   "metadata": {},
   "source": [
    "# 4. Geostandarization - web scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "223ea51b-cea0-410a-9148-1b1c0881d044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests -q\n",
    "%pip install beautifulsoup4 -q\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "255bd553-ea3f-4c81-b893-63ac19a11731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_number_from_text(text):\n",
    "    match = re.search(r'(\\d{1,3}(?:,\\d{3})*)', text)\n",
    "    return int(match.group(1).replace(',', '')) if match else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "810e698b-3d29-4a91-aabc-ac897c3efa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_population_from_table(table):\n",
    "    for header_row in table.select('tr:has(th)'):\n",
    "        th = header_row.select_one('th')\n",
    "        if 'Population' not in th.get_text():\n",
    "            continue\n",
    "\n",
    "        # next <tr> sibling (population data may be here)\n",
    "        next_row = header_row.find_next_sibling('tr')\n",
    "\n",
    "\n",
    "        # 1. population in the same row\n",
    "        td = header_row.select_one('td')\n",
    "        if td:\n",
    "            val = extract_number_from_text(td.get_text())\n",
    "            if val:\n",
    "                return val\n",
    "            \n",
    "        # 2. population in the next row <td>\n",
    "        if next_row and next_row.select_one('td'):\n",
    "            val = extract_number_from_text(next_row.select_one('td').get_text())\n",
    "            if val:\n",
    "                return val\n",
    "\n",
    "        # 3. multiple population years (bulleted list)\n",
    "        if next_row and re.match(r'\\s*â€¢\\s*\\d{4}', next_row.get_text()):\n",
    "            # select all following <tr> until a break\n",
    "            for tr in header_row.find_all_next('tr'):\n",
    "                val = extract_number_from_text(tr.get_text())\n",
    "                if val:\n",
    "                    last_val = val\n",
    "            return last_val\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7280282b-f985-47a2-babb-3189de1c7287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(url, headers, retries=3, delay_range=(1, 3)):\n",
    "    for _ in range(retries):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "            if response.status_code == 200:\n",
    "                return response\n",
    "            if response.status_code == 404:\n",
    "                return None\n",
    "        except requests.exceptions.RequestException:\n",
    "            pass\n",
    "        time.sleep(random.uniform(*delay_range))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8c83f26a-9798-477d-8591-ce2ad615a55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_infobox_table(url, headers, class_name='infobox'):\n",
    "    page = get_page(url, headers)\n",
    "    if not page:\n",
    "        return None\n",
    "    soup = bs(page.content, 'html.parser')\n",
    "    return soup.find('table', class_=class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bbf870b6-773b-4511-a1dc-b902612dcd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_population_for_city(city, headers):\n",
    "    urls = [\n",
    "        f'https://en.wikipedia.org/wiki/{city}',\n",
    "        f'https://en.wikipedia.org/wiki/{city}_(county)'\n",
    "    ]\n",
    "    for url in urls:\n",
    "        table = fetch_infobox_table(url, headers)\n",
    "        if table:\n",
    "            pop = select_population_from_table(table)\n",
    "            if pop:\n",
    "                return pop\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2c4330aa-700e-4a08-9e81-37abd7bef37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_population_for_location():\n",
    "    headers = {\"User-Agent\": \"LocationWebScrapper\"}\n",
    "\n",
    "    for city in cities:\n",
    "        population = population_cache.get(city)\n",
    "        if population is None:\n",
    "            population = get_population_for_city(city, headers)\n",
    "            if population:\n",
    "                population_cache[city] = population\n",
    "            else:\n",
    "                not_working.add(city)\n",
    "        print(f\"{city}: {population}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2793bb9e-c8ec-4cee-8e7d-a4505a68ead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_missing_info(df):\n",
    "    print(f\"Missing data in population of location: {round(df[df['LocationPopulation'].isna()]['LocationNormalized'].count() / len(df) * 100, 2)}%, {df[df['LocationPopulation'].isna()]['LocationNormalized'].count()} cases\")\n",
    "    print()\n",
    "    print(df[df['LocationPopulation'].isna()]['LocationNormalized'].value_counts()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "900e368a-fb94-4c9f-b8b2-eac4846b705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not_working = set()\n",
    "# population_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cac7ba15-24a8-4067-bcfb-9abb92bd3b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/population_cache.json', 'r', encoding='utf-8') as f:\n",
    "    population_cache = json.load(f)\n",
    "\n",
    "cities = df['LocationNormalized'].unique().tolist()\n",
    "not_working = [city for city in cities if city not in population_cache]\n",
    "\n",
    "df['LocationPopulation'] = df['LocationNormalized'].str.strip().map(lambda x: population_cache.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f206200e-2def-4ab3-95b5-6fd4eb51bf97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data in population of location: 17.59%, 43048 cases\n",
      "\n",
      "LocationNormalized\n",
      "South East London    11713\n",
      "The City              6678\n",
      "Central London        2607\n",
      "Reading               2187\n",
      "North West London     1104\n",
      "Name: count, dtype: int64\n",
      "\n",
      "not working cities:  999\n",
      "cities in cache:  1733\n"
     ]
    }
   ],
   "source": [
    "print_missing_info(df)\n",
    "print()\n",
    "print('not working cities: ', len(not_working))\n",
    "print('cities in cache: ', len(population_cache))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aff8a183-7a1c-48d5-830e-ea8d02b62b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_population_for_location()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "68169def-fcd6-40d9-84e5-531027d89376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/population_cache.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(population_cache, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617c9256",
   "metadata": {},
   "source": [
    "# 4. Geostandarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b28cea",
   "metadata": {},
   "source": [
    "## 4.1. Get population data from geonames dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3f131deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting data only for GB - turn on once (long)\n",
    "# cols = [\n",
    "#     'geonameid','name','asciiname','alternatenames','lat','lon',\n",
    "#     'feature_class','feature_code','country_code','cc2','admin1',\n",
    "#     'admin2','admin3','admin4','population','elevation','dem','tz','moddate'\n",
    "# ]\n",
    "\n",
    "# geonames = pd.read_csv(\n",
    "#     \"allCountries.txt\",\n",
    "#     sep=\"\\t\",\n",
    "#     names=cols,\n",
    "#     usecols=['asciiname', 'alternatenames', 'country_code', 'feature_code', 'feature_class', 'admin1', 'admin2', 'admin3', 'lon', 'lat', 'population'],\n",
    "#     dtype=str,\n",
    "#     header=None\n",
    "# )\n",
    "\n",
    "# geonames_gb = geonames[geonames['country_code'] == 'GB'].copy().reset_index(drop=True)\n",
    "# geonames_gb = geonames_gb[geonames_gb['feature_class'].isin(['P', 'A'])].reset_index()\n",
    "# geonames_gb.loc[geonames_gb['feature_code'] == 'PCLI', 'asciiname'] = 'UK'\n",
    "# geonames_gb.to_csv('geonames_gb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "23c7dc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "geonames_gb = pd.read_csv('geo_datasets/geonames_gb.csv')\n",
    "geonames_gb.rename(columns={'asciiname': 'name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6be49f",
   "metadata": {},
   "source": [
    "## 4.2. Get population for all locations where it is directly possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a76fae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get population for locations\n",
    "pop_dict = geonames_gb['population'].copy()\n",
    "pop_dict = geonames_gb.set_index(geonames_gb['name'].str.lower().str.strip())['population'].to_dict()\n",
    "\n",
    "pop_dict_test = geonames_gb['population'].copy()\n",
    "pop_dict_test = geonames_gb.set_index(geonames_gb['name'].str.lower().str.strip())['population'].to_dict()\n",
    "\n",
    "df['LocationPopulation'] = df['LocationNormalized'].str.lower().str.strip().map(lambda x: pop_dict.get(x))\n",
    "df_test['LocationPopulation'] = df_test['LocationNormalized'].str.lower().str.strip().map(lambda x: pop_dict_test.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0232cef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_missing_info(df):\n",
    "    print(f\"Missing data in population of location: {round(df[df['LocationPopulation'].isna()]['LocationNormalized'].count() / len(df) * 100, 2)}%, {df[df['LocationPopulation'].isna()]['LocationNormalized'].count()} cases\")\n",
    "    print()\n",
    "    print(df[df['LocationPopulation'].isna()]['LocationNormalized'].value_counts()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c22df645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data in population of location: 12.44%, 30460 cases\n",
      "\n",
      "LocationNormalized\n",
      "South East London    11713\n",
      "Central London        2607\n",
      "West Midlands         2540\n",
      "Berkshire             1502\n",
      "West Yorkshire        1072\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print_missing_info(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1574b246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data in population of location: 12.33%, 15098 cases\n",
      "\n",
      "LocationNormalized\n",
      "South East London    5714\n",
      "Central London       1347\n",
      "West Midlands        1236\n",
      "Berkshire             786\n",
      "West Yorkshire        568\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print_missing_info(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb83a5a1",
   "metadata": {},
   "source": [
    "## 4.3. Remove directions and assign population to other fitting names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3ef7c700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_population(df, location_col='LocationNormalized', pop_col='LocationPopulation', pop_dict=None):\n",
    "    directions = ['North', 'South', 'East', 'West', 'Central']\n",
    "\n",
    "    df[location_col] = df[location_col].replace(directions, '', regex=True).str.strip()\n",
    "\n",
    "    missing_mask = df[pop_col].isna()\n",
    "    missing_locations = df.loc[missing_mask, location_col].str.lower().str.strip()\n",
    "\n",
    "    pop_dict_missing = {loc: pop_dict.get(loc, np.nan) for loc in missing_locations}\n",
    "    df.loc[missing_mask, pop_col] = missing_locations.map(pop_dict_missing)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d77824ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fill_missing_population(df, pop_dict=pop_dict)\n",
    "df_test = fill_missing_population(df_test, pop_dict=pop_dict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0d7d0de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data in population of location: 4.58%, 11216 cases\n",
      "\n",
      "LocationNormalized\n",
      "Midlands                    3456\n",
      "Berkshire                   1502\n",
      "Cheshire                     871\n",
      "Yorkshire and Humberside     683\n",
      "Bedfordshire                 544\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print_missing_info(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a481c68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data in population of location: 4.55%, 5570 cases\n",
      "\n",
      "LocationNormalized\n",
      "Midlands                    1692\n",
      "Berkshire                    786\n",
      "Cheshire                     407\n",
      "Yorkshire and Humberside     333\n",
      "Bedfordshire                 272\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print_missing_info(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4a5c6a",
   "metadata": {},
   "source": [
    "## 4.4. Find population for Midlands in NUT regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "693c50b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove locations out of GB\n",
    "uk_lat_mask = (geonames_gb['lat'] >= 49) & (geonames_gb['lat'] <= 61)\n",
    "uk_lon_mask = (geonames_gb['lon'] >= -10) & (geonames_gb['lon'] <= 2)\n",
    "geonames_gb = geonames_gb[(geonames_gb['country_code'] == 'GB') & (uk_lat_mask) & (uk_lon_mask)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "152634f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts = pd.read_excel(\"geo_datasets/NUTS.xlsx\")\n",
    "nuts['NUTS118NM'] = nuts['NUTS118NM'].str.replace('(England)', '', regex=False).str.strip()\n",
    "nuts = nuts.rename(columns={'NUTS118NM': 'name', 'LONG': 'lon', 'LAT': 'lat'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c097ddaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the closest point in geonames in nuts\n",
    "from scipy.spatial import cKDTree\n",
    "tree = cKDTree(geonames_gb[['lat', 'lon']].values)\n",
    "nuts_coords = nuts[['lat', 'lon']].values\n",
    "\n",
    "distances, indices = tree.query(nuts_coords, k=1)  # k=1 -> 1 neighbour\n",
    "\n",
    "nuts['population'] = geonames_gb.iloc[indices]['population'].values\n",
    "nuts_population = dict(zip(nuts['name'], nuts['population']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "91f04a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Counter\n",
    "\n",
    "# combine West and East Midlands\n",
    "nuts_population = {**{k: v for k, v in nuts_population.items() if 'Midlands' not in k},\n",
    "                 **{'Midlands': sum(v for k, v in nuts_population.items() if 'Midlands' in k)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "01d190a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'North East': 1126,\n",
       " 'North West': 0,\n",
       " 'Yorkshire and The Humber': 0,\n",
       " 'East of England': 686,\n",
       " 'London': 10750,\n",
       " 'South East': 0,\n",
       " 'South West': 0,\n",
       " 'Wales': 0,\n",
       " 'Scotland': 8830,\n",
       " 'Northern Ireland': 0,\n",
       " 'Midlands': 50878}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nuts_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fda1c156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute nuts locations\n",
    "def impute_nuts_location(df, nuts_population):\n",
    "    population_from_dict = df['LocationNormalized'].map(nuts_population)\n",
    "    mask = ((df['LocationPopulation'].isnull()) | (df['LocationPopulation'] == 0)) & population_from_dict.notnull()\n",
    "    df.loc[mask, 'LocationPopulation'] = population_from_dict[mask]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "95c85f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = impute_nuts_location(df, nuts_population)\n",
    "df_test = impute_nuts_location(df_test, nuts_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c358fa0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data in population of location: 3.17%, 7760 cases\n",
      "\n",
      "LocationNormalized\n",
      "Berkshire                   1502\n",
      "Cheshire                     871\n",
      "Yorkshire and Humberside     683\n",
      "Bedfordshire                 544\n",
      "Edinburgh Technopole         408\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print_missing_info(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d35f5a",
   "metadata": {},
   "source": [
    "## 4.5. Cast rest of cases as 'UK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "102c9919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_uk_population(df):\n",
    "    mask = df['LocationPopulation'].isna() | (df['LocationPopulation'] == 0)\n",
    "    uk_pop = df.loc[df['LocationNormalized'].str.lower().eq('uk'), 'LocationPopulation'].dropna().iloc[0] if any(df['LocationNormalized'].str.lower().eq('uk')) else np.nan\n",
    "    df.loc[mask, ['LocationNormalized', 'LocationPopulation']] = ['UK', uk_pop]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "146ea390",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = impute_uk_population(df)\n",
    "df_test = impute_uk_population(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "432f6279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data in population of location: 0.0%, 0 cases\n",
      "\n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "print_missing_info(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2d66ad74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LocationPopulation\n",
       "66488991.0    109312\n",
       "8961989.0      45511\n",
       "541263.0        3516\n",
       "50878.0         3456\n",
       "1157603.0       3061\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['LocationPopulation'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "88225a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['LocationNormalized'], inplace=True)\n",
    "df_test.drop(columns=['LocationNormalized'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10942281-bad0-45d6-99db-4869a76753a5",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f5099241-d35c-4ee9-b8ac-268e24017a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk -q\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import word_tokenize\n",
    "%pip install gensim -q\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5fb74743-6e27-470e-bd94-5a51d4f6b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization\n",
    "def tokenize_text(text):\n",
    "    return word_tokenize(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "326a7a9d-7292-426c-a405-91291cbc36d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average vectors\n",
    "def document_vector(word_list, model, vector_size):\n",
    "    # Initialize a zero vector\n",
    "    vector = np.zeros(vector_size)\n",
    "    count = 0\n",
    "    \n",
    "    # Sum the vectors of all words in the text\n",
    "    for word in word_list:\n",
    "        if word in model.wv:\n",
    "            vector += model.wv[word]\n",
    "            count += 1\n",
    "            \n",
    "    # Return the average vector\n",
    "    if count != 0:\n",
    "        return vector / count\n",
    "    else:\n",
    "        # Return the zero vector if no words were found in the vocabulary\n",
    "        return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428ba2c2-0b03-404c-8772-3ee8ad9b5551",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = df['Title'].apply(tokenize_text).tolist()\n",
    "descriptions = df['FullDescription'].apply(tokenize_text).tolist()\n",
    "all_sentences = titles + descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178c342f-307e-4cbb-bc6f-ac9851304130",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size = 50  # output dim\n",
    "window = 5        # context window\n",
    "min_count = 5     # filter rare words\n",
    "workers = multiprocessing.cpu_count() - 1\n",
    "\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=all_sentences,\n",
    "    vector_size=vector_size,\n",
    "    window=window,\n",
    "    min_count=min_count,\n",
    "    workers=workers,\n",
    "    sg=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08adc04f-d19b-486e-9509-55d31a54e386",
   "metadata": {},
   "source": [
    "### Prepare ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e51f81-f33c-41b4-8da5-cf23a42bfe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = df['Title'].apply(lambda x: document_vector(tokenize_text(x), w2v_model, vector_size))\n",
    "descriptions = df['FullDescription'].apply(lambda x: document_vector(tokenize_text(x), w2v_model, vector_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02bf9d0-7763-41b3-9ccb-19d2d7504dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_df = pd.DataFrame(titles.tolist(), index=df.index).add_prefix('Title_vec_')\n",
    "desc_df = pd.DataFrame(descriptions.tolist(), index=df.index).add_prefix('FullDescription_vec_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78675c00-c010-45e6-a6ba-95edd8e51011",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = pd.concat([title_df, desc_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79edcc7c-9a10-4a5c-a0f7-81b9febfd5ae",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17bf258-9f33-43e4-8b93-957bf786d2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers -q\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990a8cea-9529-4015-8fad-8f5ebfcb09de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaFeatureDataset(Dataset):\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=MAX_LEN,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056f6add-4ea1-44af-b854-a70bd723a5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cls_vectors(model, data_loader, device):\n",
    "    model.eval()\n",
    "    all_cls_vectors = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Extraction [CLS] RoBERTa\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            cls_vector = outputs.last_hidden_state[:, 0, :]\n",
    "            \n",
    "            all_cls_vectors.append(cls_vector.cpu().numpy())\n",
    "\n",
    "    final_vector_array = np.concatenate(all_cls_vectors, axis=0)\n",
    "    return final_vector_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14053e30-5cef-47e2-baf5-e81b4842cdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "model_name = 'roberta-base'\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "model = RobertaModel.from_pretrained(model_name)\n",
    "model.eval()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a4ecf7-4a1b-4443-967a-3e43c47d3d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b1f1ab-703a-427d-a30e-35e55f49e94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_concat = df['Title'] + ' [SEP] ' + df['FullDescription']\n",
    "texts_list = texts_concat.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005cec1c-7a5b-42aa-99ad-7c40047c52a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RobertaFeatureDataset(texts_list)\n",
    "data_loader = DataLoader(dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399ed9cb-7abe-418b-85bf-c59b79bfa8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_vector_array = extract_cls_vectors(model, data_loader, device)\n",
    "\n",
    "texts_w2v_roberta = pd.DataFrame(\n",
    "    final_vector_array,\n",
    "    index=df.index\n",
    ")\n",
    "\n",
    "texts_w2v_roberta.columns = [f'cls_{i}' for i in range(final_vector_array.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17774ae6-31be-46c7-8f7a-d81fa9d6666c",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_w2v_roberta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd61fbe4-af65-4128-b911-e7974d0e7b7b",
   "metadata": {},
   "source": [
    "# title-uni_gram & description-roberta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eccf316-d99c-4ce9-9e25-17cd19a93b0c",
   "metadata": {},
   "source": [
    "roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8749d149-b1cf-4c61-9bd0-f9e70341b516",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers -q\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8197d826-390c-457c-913f-fdf8a0b344de",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "model_name = 'roberta-base'\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "model = RobertaModel.from_pretrained(model_name)\n",
    "model.eval()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f06a27-ad99-481f-825e-bfb16c6cdded",
   "metadata": {},
   "outputs": [],
   "source": [
    "description_ds = RobertaFeatureDataset(df['FullDescription'].tolist())\n",
    "description_dl = DataLoader(description_ds, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf11445-93b8-4b43-89e2-61b20f8a4cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_vector_array = extract_cls_vectors(model, description_dl, device)\n",
    "\n",
    "description_roberta = pd.DataFrame(\n",
    "    final_vector_array,\n",
    "    index=df.index\n",
    ")\n",
    "\n",
    "description_roberta.columns = [f'cls_{i}' for i in range(final_vector_array.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cbad08-6752-4e02-a64a-8b58324e4e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_roberta_train = description_roberta.loc[train.index]\n",
    "desc_roberta_test  = description_roberta.loc[test.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e0b6b0-e679-4b32-93ea-2729641905c1",
   "metadata": {},
   "source": [
    "tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0c1f7f-51c3-4c9d-85f0-06afafdccae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e800cc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test submission\n",
    "tfidf_title = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1, 1))\n",
    "X_test_title  = tfidf_title.transform(test[\"Title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dded364-700f-4da8-ab9c-b56ad350cf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_title = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1, 1))\n",
    "X_train_title = tfidf_title.fit_transform(train[\"Title\"])\n",
    "X_test_title  = tfidf_title.transform(test[\"Title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bd96cf-b8cd-4fa2-a76e-c8f9798190d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.extmath import randomized_svd\n",
    "\n",
    "U, Sigma, VT = randomized_svd(X_train_title, n_components=50, n_iter=5, random_state=42)\n",
    "X_train_title = U @ np.diag(Sigma)\n",
    "X_test_title  = X_test_title.dot(VT.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc17a820-5de8-4ae2-9888-4f3e3bf694f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_title.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58022e8-07cf-416b-b1c8-d587734940c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_roberta_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245dc01d-9063-4af8-a1af-6f1c447a8fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00ebd42-e73e-4f33-9f48-0015252d8a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e43cd6-b4da-4a5c-9d34-227bb43cc605",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_combined = np.concatenate([desc_roberta_train, X_train_title], axis=1)\n",
    "test_text_combined = np.concatenate([desc_roberta_test, X_test_title], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2b83c6-3fe8-49be-8825-d7050c764c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_combined_df = pd.DataFrame(train_text_combined)\n",
    "test_text_combined_df = pd.DataFrame(test_text_combined)\n",
    "\n",
    "train_text_combined_df.to_parquet('data/texts_uni_roberta_train.parquet', index=True)\n",
    "test_text_combined_df.to_parquet('data/texts_uni_roberta_test.parquet',  index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a7b531",
   "metadata": {},
   "source": [
    "# 5. Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3b9abe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabular\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, val = train_test_split(df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b920781-6aee-45e9-b382-948ac10263e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec\n",
    "texts_train = texts.loc[train.index]\n",
    "texts_val = texts.loc[val.index]\n",
    "texts_train.to_pickle('data/texts_w2v_train.pkl')\n",
    "texts_val.to_pickle('data/texts_w2v_val.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ecc191-682b-4827-890e-c977f3dd56cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roberta\n",
    "texts_roberta_train = texts_w2v_roberta.loc[train.index]\n",
    "texts_roberta_test  = texts_w2v_roberta.loc[val.index]\n",
    "texts_roberta_train.to_parquet('data/texts_roberta_train.parquet', index=True)\n",
    "texts_roberta_test.to_parquet('data/texts_roberta_test.parquet',  index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80709e3b",
   "metadata": {},
   "source": [
    "# 6. One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0789ee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select most common source in category group\n",
    "category_to_source = train.groupby('Category')['SourceName'].agg(lambda x: x.mode()[0]).to_dict()\n",
    "train['SourceName'] = train['Category'].map(category_to_source)\n",
    "val['SourceName'] = val['Category'].map(category_to_source)\n",
    "df_test['SourceName'] = df_test['Category'].map(category_to_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "373175d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train, columns = ['ContractType', 'ContractTime', 'Category', 'SourceName'], drop_first=True, dtype=int)\n",
    "val = pd.get_dummies(val, columns = ['ContractType', 'ContractTime', 'Category', 'SourceName'], drop_first=True, dtype=int)\n",
    "test = pd.get_dummies(df_test, columns = ['ContractType', 'ContractTime', 'Category', 'SourceName'], drop_first=True, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376308cb",
   "metadata": {},
   "source": [
    "# 7. Target Encoding - mean salary of company instead of company name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ca8aed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining companies by two first words\n",
    "train['CompanyPrefix'] = train['Company'].apply(lambda x: ' '.join(str(x).split()[:2]))\n",
    "val['CompanyPrefix'] = val['Company'].apply(lambda x: ' '.join(str(x).split()[:2]))\n",
    "test['CompanyPrefix'] = test['Company'].apply(lambda x: ' '.join(str(x).split()[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "34bf2f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean salary by company\n",
    "mean_company = train.groupby('CompanyPrefix')['SalaryNormalized'].mean()\n",
    "train['CompanyEncoded'] = train['CompanyPrefix'].map(mean_company)\n",
    "val['CompanyEncoded'] = val['CompanyPrefix'].map(mean_company)\n",
    "test['CompanyEncoded'] = test['CompanyPrefix'].map(mean_company)\n",
    "\n",
    "# filling not existing companies in test with global mean\n",
    "global_mean = train['SalaryNormalized'].mean()\n",
    "val['CompanyEncoded'] = val['CompanyEncoded'].fillna(global_mean)\n",
    "test['CompanyEncoded'] = test['CompanyEncoded'].fillna(global_mean)\n",
    "\n",
    "train.drop(columns=['Company', 'CompanyPrefix'], inplace=True)\n",
    "val.drop(columns=['Company', 'CompanyPrefix'], inplace=True)\n",
    "test.drop(columns=['Company', 'CompanyPrefix'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "543cdd4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompanyPrefix\n",
       ".Michael Page    77500.000000\n",
       "1 1              24462.857143\n",
       "10 TRINITY       45000.000000\n",
       "100 percent      40500.000000\n",
       "100% IT          40750.000000\n",
       "Name: SalaryNormalized, dtype: float64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_company.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0a04e3",
   "metadata": {},
   "source": [
    "# 9. Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "bc229695-cee3-4544-ac30-19b9433c8ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1005a456-808b-4e7d-ba19-25bc397d60eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_tfidf(df, n_grams):\n",
    "    tfidf_description = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=n_grams)\n",
    "    tfidf_title = TfidfVectorizer(max_features=1000, stop_words='english', ngram_range=n_grams)\n",
    "\n",
    "    X_description = tfidf_description.fit_transform(df[\"FullDescription\"])\n",
    "    X_title = tfidf_title.fit_transform(df[\"Title\"])\n",
    "\n",
    "    return hstack([X_description, X_title]), tfidf_description, tfidf_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cae80d2c-4e1b-4fcc-8397-346a9fb48821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_tfidf(df, tfidf_description, tfidf_title):\n",
    "    X_description = tfidf_description.transform(df[\"FullDescription\"])\n",
    "    X_title = tfidf_title.transform(df[\"Title\"])\n",
    "\n",
    "    return hstack([X_description, X_title])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800a54ca-0d95-4de0-aad7-484791fbb4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train completed\n",
      "val completed\n",
      "tdidf test completed\n"
     ]
    }
   ],
   "source": [
    "X_train_text, tfidf_description, tfidf_title = prepare_tfidf(train, n_grams=(1, 1))\n",
    "print('train completed')\n",
    "X_val_text = transform_tfidf(val, tfidf_description, tfidf_title)\n",
    "print('val completed')\n",
    "X_test_text = transform_tfidf(test, tfidf_description, tfidf_title)\n",
    "print('tdidf test completed')\n",
    "\n",
    "# dimenshion reduction\n",
    "svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "\n",
    "X_train_text = svd.fit_transform(X_train_text)\n",
    "print('svd train completed')\n",
    "X_val_text = svd.transform(X_val_text)\n",
    "print('svd val completed')\n",
    "X_test_text = svd.transform(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddb212d-6a36-4799-bcf3-c9c247cb630d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving\n",
    "ngram = 'uni'  # 'uni', 'bi', 'tri'...\n",
    "np.save(f\"data/X_train_text_{ngram}.npy\", X_train_text)\n",
    "np.save(f\"data/X_val_text_{ngram}.npy\", X_val_text)\n",
    "np.save(f\"data/X_test_text_{ngram}.npy\", X_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee79a33b",
   "metadata": {},
   "source": [
    "# 10. Tabular data saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1801df57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tab = train.drop(columns=['Title', 'FullDescription'])\n",
    "val_tab = val.drop(columns=['Title', 'FullDescription'])\n",
    "test_tab = test.drop(columns=['Title', 'FullDescription'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9088e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tab.to_csv('data/train_preprocessed.csv', index=False)\n",
    "val_tab.to_csv('data/val_preprocessed.csv', index=False)\n",
    "test_tab.to_csv('data/test_preprocessed.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff0ee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tab.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7434fd-43f6-4d29-9eb5-747a7e46d57d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
